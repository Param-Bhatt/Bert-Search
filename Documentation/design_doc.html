<!DOCTYPE html>
<html lang="en">

<head>
  <title>Design Document</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
  <link href='https://fonts.googleapis.com/css?family=Cinzel Decorative' rel='stylesheet'>

  <style>
    .row.content {
      margin-top: 5%;
    }

    body {
      font-family: 'Times New Roman', Times, serif;
      font-size: 18px;
    }

    table,
    th,
    td {
      border: 1px solid black;
    }

    th,
    td {
      padding: 15px 15px;
    }

    table {
      border-spacing: 5px;
    }
  </style>
</head>

<body style="background-color:rgb(47, 48, 49); color:snow;padding-bottom: 5%;">
  <div class="container-fluid     ">
    <div class="row content">
      <div class="col-sm-8 col-sm-offset-2 ">
        <b>
          <p class="text-center" style="font-size: 35px;">An Information Retrieval System <br><i
              style="font-size: 20px;">(through emails), (used Python)</i></p>
        </b>
        <hr>
        <b class="text-center" style="font-size: 28px"> Roadmap & Architecture</b>
        <hr>
        <b class="text-left" style="font-size: 25px;">Architecture</b>
        <p style="padding-left: 5%;"> We have chosen an architecture similar to the microservices architecture where we
          have broken down each functionality to it's smallest component.</p>
        <br><b class="text-left" style="font-size: 25px;">Our dataset choice</b>
        <ul>
          <li>We have implemented an Information Retrieval system to search for relevant emails from a dataset of Enron
            Corporation. Their emails were leaked into the public and it was reviled that they were fraud organisation.
          </li>
          <li>We chose this dataset as it had a lot of emails and they were generic and formal which gave us a
            well-paved way to find a lot of words in our pretrained embeddings corpus.</li>
        </ul>
        <br><b class="text-left" style="font-size: 25px;">Loading the dataset</b>

        <ul>The dataset that we have used here is a dataset containing multiple emails.
          This dataset is popularly available and free to use. We have a global variable document which is a list of strings where each string corresponds to an email. The email is broken at <i>\n</i> and queried as independent sentences. 
        </ul>
        <br>

        <b class="text-left" style="font-size: 25px;">Pre-processing the Data</b>

        <ul>We have used the stop words and lemmatizers from nltk library itself for our preprocessing. A function
          pre-process has been used for preprocessing each individual string of the mails.
          <li> In the function , first we convert all the strings to lower case.</li>
          <li> Then we sanitize our emails ,i.e., remove unwanted special characters, blank spaces etc and keep our
            input limited to the english characters and numbers.</li>
          <li> Then we remove the existing stopwords in the string and lemmatize our string.</li>
          <li> It finally returns our pre-processed string.</li>
        </ul>
        <br>

        <b class="text-left" style="font-size: 25px;">Embedding our data</b>

        <ul>Once we have our pre-processed data, we need a way to determine the relevance of specific strings among each
          other. For this , we used 2 different types of pretrained embeddings and compared their results as well :
          <ol>
            <li>BERT Embedding</li>
            <li>Glove Embedding</li>
          </ol>
          <li> We iterate through each mail here, and embed them using bert first. We then store it in a pickl file , to
            not only help with the storage size but also for a quicker and faster retrieval.</li>
          <li> We iterate through each mail here, and embed them now using glove. We then store it in a pickl file , to
            not only help with the storage size but also for a quicker and faster retrieval.</li>
          <li> For testing purposes , we have also stored both pre-processed and normal data from the dataset. This
            helped us understand what difference the preprocessing makes , and how it affects our performance .</li>
        </ul>
        <br>

        <b class="text-left" style="font-size: 25px;">Searching for a string</b>

        <ul>Now that we have our embedded dataset ready , we are good to go for searching.:

          <li> We take in the query string from the user.</li>
          <li> Once again , we preprocess the query using the same preprocess function that we have used to preprocess
            our dataset.</li>
          <li> Now, we run the embedding on our query. After this step, we have both our query and dataset in the
            embedded form.</li>
          <li> Now , we calculate the cosine scores between each string in the email and our string , in a dynamic
            array.</li>
          <li> We list out the queries , their cosine scores , the email in which the query was found , and the line in
            the email at which the query was found. These are listed out in the descending order.</li>
          <li> Our function uses a default argument of 3 results to be listed out, however, we can add it in the query
            function to get more query results.</li>
        </ul>
        <br>


        <hr>
        <b class="text-center" style="font-size: 28px"> Libraries Used</b>
        <hr>
        <ul>
          <li>datasets : <i>This has been used to get our email corpus </i></li>
          <li>nltk : <i>This has been used for
              pre-processing our dataset. We used it to lemmatize
              our
              dataset and remove the stop words from it.</i></li>
          <li>numpy : <i>This library has been used to work with arrays and
              apply linear algebra concepts.</i></li>
          <li>pickle : <i>This has been used to store our built index in
              a .pkl file,</i></li>
          <li>mxnet : <i>This has been used so that we can interface the
              gpu using cuda library. This results in
              reduction
              of processing time from 4h 53min (Colab CPU) to 7mins (Nvidia Tesla T4). </i></li>
          <li>gluonnlp : <i>This was a dependency for mxnet to interface with cuda.</i></li>
          <li>bert-embedding : <i>This has been used to get the pretrained bert embeddings of our words.</i></li>
          <li>re(regex) : <i>This is a regular expression library to work on a
              set of strings.</i></li>

        </ul>
        <hr>
        <b class="text-center" style="font-size: 28px"> Data Structures and Algorithms with their Justification</b>
        <hr>
        We have majorly used 3 data structures:<br><br>
        <ul>
          <li>
            <b>String</b> : It is used in multiple function calls and instances. This data type forms the basis of our
            dataset.<br><br>
            <i>Justification:</i> From query to the email output almost everything is a sequence of characters, String
            is most obvious structure to use in such cases. They can be efficiently managed and can be split by space to
            get
            <ul>
              <li>
                Individual words to remove stopwords, and find embeddings
                <ul>
                  <li>bert-embedding gets strings and finds each embeddings of each word in it.</li>
                  <li>glove embeddings are stored in a dictionary which have words in the form of strings as keys for
                    indexing.</li>
                </ul>
              </li>
              <br>
              <li>
                Individual sentences to find the most similar ones
                <ul>
                  <li>
                    We have queried for similarity with each sentence and this means to find each sentence which is very
                    efficient and convenient once we use strings.
                  </li>
                </ul>
              </li>
            </ul>
          </li>
          <br>
          <li>
            Lists : It has been used to store multiple strings. Our corpus is made up of a list of strings.
            <br><br>
            <i>Justification:</i> Lists make it very convenient to handel large dimensional data, the embeddings of each
            word is a large (300, 768) dimentional data. The usage of lists help us by:
            <br><br>
            <ul>
              <li>
                Finding Cosine Score is very streamlined when we use lists.
                <ul>
                  <li>
                    numpy library has inbuilt function to find the dot product which takes a list as input.
                  </li>
                  <li>
                    Dividing the cosine by the magnitude of the large embedding is easily possible by numpy making the
                    process efficient and convinient.
                  </li>
                </ul>
              </li><br>
              <li>
                Sorting the resultant cosing scores
                <ul>
                  <li>
                    Cosine scores are returned as an array where we need to sort them to get the top scores. This is
                    most conviniently and efficiently done in the data structure of array. This is one of the
                    functonality of numpy, streamiling the task.
                  </li>
                </ul>
              </li>
            </ul>
          </li><br>

          <li>
            Dictionary : This data structure has key and value pairs where the key in the structure gives value.<br><br>
            <i>Justification :</i> We have used this for creating our references from line to email. This is used to
            streamline and make the structure more readable and easier to access.<br><br>
            <ul>
              <li>
                Dictionary makes our indexing bound to not only numbers, it enables us to use string references to
                access the data.
              </li><br>
              <li>
                We have an index reference dictionary which maps line number in the corpus to the email it belongs and
                the start line number of the email, if we were to do it in an array, we would have to search through an
                array which would have been linear or at best logarithmic whereas, in a dictionary, we have
                near-constant access time.
              </li><br>
            </ul>
          </li>
          <li>
            Dictionary of Lists: In this data structure we have a dictionary mapping to a list.<br><br>
            <i>Justification : </i> The dataset is loaded in 3 parts <i>Test, Train</i> and <i>Validation</i>, where
            each is a dictionary having <i>email_body</i> and <i>subject_line</i> for each mail, so we have a list of
            mails and their corresponding subject line split into test, train, and validation, for storing this the best
            data structure is a dictionary mapping to a list.<br>
            This kind of usage makes the structure very intuitive, as the people who will be using this will be new and
            an array structure will not intuivitively give them understanding, what index is subject and what is mail
            body.
          </li>
        </ul>
        <hr>

        <h3>Run-Time Analysis of our Search Engine: </h3>
        <hr>


        <h3>
          Building the Indexes with and without preprocessing for both the embeddings, we found the following :
        </h3>
        <ul>
          <li>
            Preprocessing is actually faster in processing as it reduces the length of words to process because it
            discards words not in the embeddings, BERT does a better job as it tries to find the embeddings of
            subwords to find the meaning, rather than just discarding the sentence.
          </li><br>
          <li>
            BERT is highly parallel as the CPU user time is higher than the wall time, meaning that CPU worked more
            time that what elapsed in the real word, this is because the CPU is multithreaded.
          </li>
        </ul>
        <h3>The graphical analysis is shown below :</h3>
        <img src="resources/Index.jpeg" style="width: 100%; height: auto;"><br><br>
        <img src="resources/Query.jpeg" style="width: 100%; height: auto;">
        <br><br>
        <p style="font-size: 20px;">
          <t>
            Here we can clearly see the difference of time taken by models:<br><br>
            <ol>
              <li>
                The major difference in index building time in BERT and Glove is because for Glove we are reading
                the Embeddings from the dictionary, whereas for BERT we have to find the embeddings which is
                compute intensive. This is highly parallelized due to this implementation on GPU.
              </li><br>
              <li>
                The difference in the query search time is very minuscule as here we are iterating through the
                Index and finding for the cosine score. Since glove doesn't have embeddings for every word it
                skips maky sentences in the dataset which makes it lose information, decreasing the quantum it
                has to traverse.
              </li>
            </ol>
          </t>
        </p>

        <br>

      </div>

    </div>

  </div>